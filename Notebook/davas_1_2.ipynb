{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j4ramm0vmvh"
      },
      "source": [
        "# Domain Adaptation Via Activation Shaping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-LqKzY-vmvp"
      },
      "source": [
        "**Teacher assistant** Iurada Leonardo\n",
        "\n",
        "**Students**\n",
        "\n",
        "- Bar Giorgio\n",
        "- Distefano Giuseppe\n",
        "- Incaviglia Salvatore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1K5BCgevmvr"
      },
      "source": [
        "## 0 - Reproduce the Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GNDC97Lvmvs"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yj0xpGOvmvs",
        "outputId": "efcd19e0-8d69-44ea-d983-45aa31726bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision tqdm torchmetrics\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.backends.mps\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import os\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QL6QFg7vmvv"
      },
      "source": [
        "### Setup PACS dataset and environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU25YTvRvmvw",
        "outputId": "0245805a-6634-4a92-9884-359983d00d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 10032, done.\u001b[K\n",
            "remote: Total 10032 (delta 0), reused 0 (delta 0), pack-reused 10032\u001b[K\n",
            "Receiving objects: 100% (10032/10032), 174.13 MiB | 22.11 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (9993/9993), done.\n",
            "Cloning into 'DANN_Template'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23\u001b[K\n",
            "Receiving objects: 100% (23/23), 33.86 KiB | 642.00 KiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ],
      "source": [
        "# Download PACS Dataset Images and Labels\n",
        "!git clone https://github.com/MachineLearning2020/Homework3-PACS/\n",
        "!git clone https://github.com/silvia1993/DANN_Template/\n",
        "\n",
        "# Setup data\n",
        "!rm -rf data || true\n",
        "!rm -rf record || true\n",
        "!mkdir data\n",
        "!mkdir data/kfold\n",
        "!cp -r Homework3-PACS/PACS/ data/kfold\n",
        "!cp DANN_Template/txt_lists/*.txt data\n",
        "!rm -rf Homework3-PACS/\n",
        "!rm -rf DANN_Template/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCGGDU0Yvmvx"
      },
      "source": [
        "### Globals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks2GUIKUvmvx"
      },
      "source": [
        "#### globals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CKy4Lcn5vmvy"
      },
      "outputs": [],
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "CONFIG = dotdict({})\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    CONFIG.device = 'cuda'\n",
        "elif torch.backends.mps.is_available() and \\\n",
        "    torch.backends.mps.is_built():\n",
        "    CONFIG.device = 'mps'\n",
        "else:\n",
        "    CONFIG.device = 'cpu'\n",
        "\n",
        "CONFIG.dtype = torch.float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X-3ocOEvmvy"
      },
      "source": [
        "#### parse args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ri1QrU7_vmvz"
      },
      "outputs": [],
      "source": [
        "def _clear_args(parsed_args):\n",
        "    parsed_args.experiment_args = eval(parsed_args.experiment_args)\n",
        "    parsed_args.dataset_args = eval(parsed_args.dataset_args)\n",
        "    return parsed_args\n",
        "\n",
        "\n",
        "def parse_arguments():\n",
        "    parser = ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--seed', type=int, default=0, help='Seed used for deterministic behavior')\n",
        "    parser.add_argument('--test_only', action='store_true', help='Whether to skip training')\n",
        "    parser.add_argument('--cpu', action='store_true', help='Whether to force the usage of CPU')\n",
        "\n",
        "    parser.add_argument('--experiment', type=str, default='baseline')\n",
        "    parser.add_argument('--experiment_name', type=str, default='baseline')\n",
        "    parser.add_argument('--experiment_args', type=str, default='{}')\n",
        "    parser.add_argument('--dataset_args', type=str, default='{}')\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=128)\n",
        "    parser.add_argument('--epochs', type=int, default=30)\n",
        "    parser.add_argument('--num_workers', type=int, default=5)\n",
        "    parser.add_argument('--grad_accum_steps', type=int, default=1)\n",
        "\n",
        "    return _clear_args(parser.parse_args())\n",
        "\n",
        "\n",
        "def parse_fake_arguments(conf):\n",
        "    parser = ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--seed', type=int, default=0, help='Seed used for deterministic behavior')\n",
        "    parser.add_argument('--test_only', action='store_true', help='Whether to skip training')\n",
        "    parser.add_argument('--cpu', action='store_true', help='Whether to force the usage of CPU')\n",
        "\n",
        "    parser.add_argument('--experiment', type=str, default='baseline')\n",
        "    #parser.add_argument('--experiment_name', type=str, default='baseline')\n",
        "    if conf=='cartoon': parser.add_argument('--experiment_name', type=str, default='baseline/cartoon')\n",
        "    elif conf=='sketch': parser.add_argument('--experiment_name', type=str, default='baseline/sketch')\n",
        "    elif conf=='photo': parser.add_argument('--experiment_name', type=str, default='baseline/photo')\n",
        "    else: parser.add_argument('--experiment_name', type=str, default='baseline/cartoon')\n",
        "    parser.add_argument('--experiment_args', type=str, default='{}')\n",
        "    #parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': '${target_domain}'}\")\n",
        "    if conf=='cartoon': parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': 'cartoon'}\")\n",
        "    elif conf=='sketch': parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': 'sketch'}\")\n",
        "    elif conf=='photo': parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': 'photo'}\")\n",
        "    else: parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': 'cartoon'}\")\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=128)\n",
        "    parser.add_argument('--epochs', type=int, default=30)\n",
        "    parser.add_argument('--num_workers', type=int, default=5)\n",
        "    parser.add_argument('--grad_accum_steps', type=int, default=1)\n",
        "\n",
        "    return _clear_args(parser.parse_args())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7_xoRWhvmvz"
      },
      "source": [
        "#### Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GA15sREQvmvz"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "NUM_CLASSES = 7\n",
        "BATCH_SIZE = 256\n",
        "LR = 1e-3               # The initial Learning Rate\n",
        "MOMENTUM = 0.9          # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5     # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 30         # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20          # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1             # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjcULfoOvmv0"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2juNIEQ9vmv0"
      },
      "source": [
        "#### utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XSPzZSuSvmv0"
      },
      "outputs": [],
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, examples, transform):\n",
        "        self.examples = examples\n",
        "        self.T = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.examples[index]\n",
        "        x = Image.open(x).convert('RGB')\n",
        "        x = self.T(x).to(CONFIG.dtype)\n",
        "        y = torch.tensor(y).long()\n",
        "        return x, y\n",
        "\n",
        "######################################################\n",
        "# TODO: modify 'BaseDataset' for the Domain Adaptation setting.\n",
        "# Hint: randomly sample 'target_examples' to obtain targ_x\n",
        "#class DomainAdaptationDataset(Dataset):\n",
        "#    def __init__(self, source_examples, target_examples, transform):\n",
        "#        self.source_examples = source_examples\n",
        "#        self.target_examples = target_examples\n",
        "#        self.T = transform\n",
        "#\n",
        "#    def __len__(self):\n",
        "#        return len(self.source_examples)\n",
        "#\n",
        "#    def __getitem__(self, index):\n",
        "#        src_x, src_y = ...\n",
        "#        targ_x = ...\n",
        "#\n",
        "#        src_x = self.T(src_x)\n",
        "#        targ_x = self.T(targ_x)\n",
        "#        return src_x, src_y, targ_x\n",
        "\n",
        "# [OPTIONAL] TODO: modify 'BaseDataset' for the Domain Generalization setting.\n",
        "# Hint: combine the examples from the 3 source domains into a single 'examples' list\n",
        "#class DomainGeneralizationDataset(Dataset):\n",
        "#    def __init__(self, examples, transform):\n",
        "#        self.examples = examples\n",
        "#        self.T = transform\n",
        "#\n",
        "#    def __len__(self):\n",
        "#        return len(self.examples)\n",
        "#\n",
        "#    def __getitem__(self, index):\n",
        "#        x1, x2, x3 = self.examples[index]\n",
        "#        x1, x2, x3 = self.T(x1), self.T(x2), self.T(x3)\n",
        "#        targ_x = self.T(targ_x)\n",
        "#        return x1, x2, x3\n",
        "\n",
        "######################################################\n",
        "\n",
        "class SeededDataLoader(DataLoader):\n",
        "    def __init__(self, dataset: Dataset, batch_size=1, shuffle=None,\n",
        "                 sampler=None,\n",
        "                 batch_sampler=None,\n",
        "                 num_workers=0, collate_fn=None,\n",
        "                 pin_memory=False, drop_last=False, timeout=0,\n",
        "                 worker_init_fn=None, multiprocessing_context=None,\n",
        "                 generator=None, *, prefetch_factor=None, persistent_workers=False,\n",
        "                 pin_memory_device=\"\"):\n",
        "\n",
        "        if not CONFIG.use_nondeterministic:\n",
        "            def seed_worker(worker_id):\n",
        "                worker_seed = torch.initial_seed() % 2**32\n",
        "                np.random.seed(worker_seed)\n",
        "                random.seed(worker_seed)\n",
        "\n",
        "            generator = torch.Generator()\n",
        "            generator.manual_seed(CONFIG.seed)\n",
        "\n",
        "            worker_init_fn = seed_worker\n",
        "\n",
        "        super().__init__(dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn,\n",
        "                         pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator,\n",
        "                         prefetch_factor=prefetch_factor, persistent_workers=persistent_workers,\n",
        "                         pin_memory_device=pin_memory_device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8COjLe2Fvmv0"
      },
      "source": [
        "#### PACS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qJ3cq4Ofvmv1"
      },
      "outputs": [],
      "source": [
        "def get_transform(size, mean, std, preprocess):\n",
        "    transform = []\n",
        "    if preprocess:\n",
        "        transform.append(T.Resize(256))\n",
        "        transform.append(T.RandomResizedCrop(size=size, scale=(0.7, 1.0)))\n",
        "        transform.append(T.RandomHorizontalFlip())\n",
        "    else:\n",
        "        transform.append(T.Resize(size))\n",
        "    transform.append(T.ToTensor())\n",
        "    transform.append(T.Normalize(mean, std))\n",
        "    return T.Compose(transform)\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    CONFIG.num_classes = 7\n",
        "    CONFIG.data_input_size = (3, 224, 224)\n",
        "\n",
        "    # Create transforms\n",
        "    mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225) # ImageNet Pretrain statistics\n",
        "    train_transform = get_transform(size=224, mean=mean, std=std, preprocess=True)\n",
        "    test_transform = get_transform(size=224, mean=mean, std=std, preprocess=False)\n",
        "\n",
        "    # Load examples & create Dataset\n",
        "    if CONFIG.experiment in ['baseline', 'random']:\n",
        "        source_examples, target_examples = [], []\n",
        "\n",
        "        # Load source\n",
        "        #with open(os.path.join(CONFIG.dataset_args['text_root'], f\"{CONFIG.dataset_args['source_domain']}.txt\"), 'r') as f:\n",
        "            #lines = f.readlines()\n",
        "        # domain/category/sample n\n",
        "        f = open(os.path.join(CONFIG.dataset_args['text_root'], f\"{CONFIG.dataset_args['source_domain']}.txt\"), 'r')\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            path, label = line[0].split('/')[0:], int(line[1])\n",
        "            source_examples.append((os.path.join(CONFIG.dataset_args['images_root'], *path), label))\n",
        "        f.close()\n",
        "\n",
        "        # Load target\n",
        "        #with open(os.path.join(CONFIG.dataset_args['text_root'], f\"{CONFIG.dataset_args['target_domain']}.txt\"), 'r') as f:\n",
        "            #lines = f.readlines()\n",
        "        f = open(os.path.join(CONFIG.dataset_args['text_root'], f\"{CONFIG.dataset_args['target_domain']}.txt\"), 'r')\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            path, label = line[0].split('/')[0:], int(line[1])\n",
        "            target_examples.append((os.path.join(CONFIG.dataset_args['images_root'], *path), label))\n",
        "        f.close()\n",
        "\n",
        "        train_dataset = BaseDataset(source_examples, transform=train_transform)\n",
        "        test_dataset = BaseDataset(target_examples, transform=test_transform)\n",
        "\n",
        "    ######################################################\n",
        "    #elif... TODO: Add here how to create the Dataset object for the other experiments\n",
        "\n",
        "\n",
        "    ######################################################\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader = SeededDataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=CONFIG.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=CONFIG.num_workers,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    test_loader = SeededDataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=CONFIG.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=CONFIG.num_workers,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    return {'train': train_loader, 'test': test_loader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDUK98dRvmv1"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRb0wPBTvmv1"
      },
      "source": [
        "#### ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RT5Z64b0vmv1"
      },
      "outputs": [],
      "source": [
        "class BaseResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseResNet18, self).__init__()\n",
        "        self.resnet = resnet18(weights=ResNet18_Weights)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "######################################################\n",
        "# TODO: either define the Activation Shaping Module as a nn.Module\n",
        "#class ActivationShapingModule(nn.Module):\n",
        "#...\n",
        "#\n",
        "# OR as a function that shall be hooked via 'register_forward_hook'\n",
        "#def activation_shaping_hook(module, input, output):\n",
        "#...\n",
        "#\n",
        "######################################################\n",
        "# TODO: modify 'BaseResNet18' including the Activation Shaping Module\n",
        "#class ASHResNet18(nn.Module):\n",
        "#    def __init__(self):\n",
        "#        super(ASHResNet18, self).__init__()\n",
        "#        ...\n",
        "#\n",
        "#    def forward(self, x):\n",
        "#        ...\n",
        "#\n",
        "######################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSD7qmGTvmv2"
      },
      "source": [
        "### Training functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "\n",
        "    acc_meter = Accuracy(task='multiclass', num_classes=CONFIG.num_classes)\n",
        "    acc_meter = acc_meter.to(CONFIG.device)\n",
        "\n",
        "    loss = [0.0, 0]\n",
        "    for x, y in tqdm(data):\n",
        "        with torch.autocast(device_type=CONFIG.device, dtype=torch.float16, enabled=True):\n",
        "            x, y = x.to(CONFIG.device), y.to(CONFIG.device)\n",
        "            logits = model(x)\n",
        "            acc_meter.update(logits, y)\n",
        "            loss[0] += F.cross_entropy(logits, y).item()\n",
        "            loss[1] += x.size(0)\n",
        "\n",
        "    accuracy = acc_meter.compute()\n",
        "    loss = loss[0] / loss[1]\n",
        "    logging.info(f'Accuracy: {100 * accuracy:.2f} - Loss: {loss}')\n",
        "    print(f'Accuracy: {100 * accuracy:.2f} - Loss: {loss} \\n')\n",
        "\n",
        "\n",
        "def train(model, data):\n",
        "\n",
        "    # Create optimizers & schedulers\n",
        "    optimizer = torch.optim.SGD(model.parameters(), weight_decay=0.0005, momentum=0.9, nesterov=True, lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(CONFIG.epochs * 0.8), gamma=0.1)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "\n",
        "    # Load checkpoint (if it exists)\n",
        "    cur_epoch = 0\n",
        "    if os.path.exists(os.path.join('record', CONFIG.experiment_name, 'last.pth')):\n",
        "        checkpoint = torch.load(os.path.join('record', CONFIG.experiment_name, 'last.pth'))\n",
        "        cur_epoch = checkpoint['epoch']\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "\n",
        "    # Optimization loop\n",
        "    for epoch in range(cur_epoch, CONFIG.epochs):\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, batch in enumerate(tqdm(data['train'])):\n",
        "\n",
        "            # Compute loss\n",
        "            with torch.autocast(device_type=CONFIG.device, dtype=torch.float16, enabled=True):\n",
        "\n",
        "                if CONFIG.experiment in ['baseline', 'random']:\n",
        "                    x, y = batch\n",
        "                    x, y = x.to(CONFIG.device), y.to(CONFIG.device)\n",
        "                    loss = F.cross_entropy(model(x), y)\n",
        "\n",
        "                ######################################################\n",
        "                #elif... TODO: Add here train logic for the other experiments\n",
        "\n",
        "                ######################################################\n",
        "\n",
        "            # Optimization step\n",
        "            scaler.scale(loss / CONFIG.grad_accum_steps).backward()\n",
        "\n",
        "            if ((batch_idx + 1) % CONFIG.grad_accum_steps == 0) or (batch_idx + 1 == len(data['train'])):\n",
        "                scaler.step(optimizer)\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                scaler.update()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Test current epoch\n",
        "        logging.info(f'[TEST @ Epoch={epoch}]')\n",
        "        evaluate(model, data['test'])\n",
        "\n",
        "        # Save checkpoint\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'model': model.state_dict()\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join('record', CONFIG.experiment_name, 'last.pth'))\n"
      ],
      "metadata": {
        "id": "l4EOCo5CvL4M"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run (baseline)"
      ],
      "metadata": {
        "id": "a02osy2KvrL-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98_3TWLTvmv2",
        "outputId": "e52be004-7a0d-491d-b3e4-345dabfc4e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 152MB/s]\n",
            "100%|██████████| 16/16 [00:11<00:00,  1.45it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 60.78 - Loss: 0.011620737050107853 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.75it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 79.82 - Loss: 0.006599299101058594 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:11<00:00,  1.42it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 87.78 - Loss: 0.0041108920545635105 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.63it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 89.40 - Loss: 0.00310309904064247 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.61it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.14 - Loss: 0.0024948941287166342 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.63it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 92.16 - Loss: 0.0021858058602153185 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.64it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 92.69 - Loss: 0.0019666722479337703 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.63it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.17 - Loss: 0.0018043650704586576 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.66it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.53 - Loss: 0.0017245613350839672 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.61it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.13 - Loss: 0.0015787166303503298 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.59it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.31 - Loss: 0.0015136572080636454 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.61it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.37 - Loss: 0.0014615919351756216 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.62it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.91 - Loss: 0.0013111949937340028 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.67it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.85 - Loss: 0.0013379836811901566 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.73it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.85 - Loss: 0.0013176740699274811 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.83it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.21 - Loss: 0.0012480593158188695 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.90it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.63 - Loss: 0.0011855909154711369 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.99it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.81 - Loss: 0.001148534507607807 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.95it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.39 - Loss: 0.0011825696860780258 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.99it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.51 - Loss: 0.0011261282310246706 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.57 - Loss: 0.00110271982625573 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  2.00it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.63 - Loss: 0.0010885661646366834 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.65it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.81 - Loss: 0.001059915064025425 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  2.00it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.69 - Loss: 0.001080644929859631 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.99it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.63 - Loss: 0.0010905734570083505 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  2.00it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.75 - Loss: 0.0010759724281772882 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.97it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.75 - Loss: 0.0010753345932298436 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.98it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.81 - Loss: 0.001072866622425482 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.94it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.69 - Loss: 0.001083402799074343 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.89it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.81 - Loss: 0.0010701698529907687 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Load dataset\n",
        "    data = load_data()\n",
        "\n",
        "    # Load model\n",
        "    if CONFIG.experiment in ['baseline']:\n",
        "        model = BaseResNet18()\n",
        "\n",
        "    ######################################################\n",
        "    #elif... TODO: Add here model loading for the other experiments (eg. DA and optionally DG)\n",
        "\n",
        "    ######################################################\n",
        "\n",
        "    model.to(CONFIG.device)\n",
        "\n",
        "    if not CONFIG.test_only:\n",
        "        train(model, data)\n",
        "    else:\n",
        "        evaluate(model, data['test'])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "    # Parse arguments (uncomment only one of the following)\n",
        "    '''\n",
        "    confs = [\n",
        "        { # Cartoon\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'baseline',\n",
        "            'experiment_name': 'baseline/cartoon/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'cartoon'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        }\n",
        "    ]\n",
        "    '''\n",
        "    '''\n",
        "    confs = [\n",
        "        { # Sketch\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'baseline',\n",
        "            'experiment_name': 'baseline/sketch/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'sketch'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        }\n",
        "    ]\n",
        "    '''\n",
        "    confs = [\n",
        "        { # Photo\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'baseline',\n",
        "            'experiment_name': 'baseline/photo/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'photo'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    #args = parse_arguments()\n",
        "    for conf in confs:\n",
        "        args = argparse.Namespace(**conf)\n",
        "        CONFIG.update(vars(args))\n",
        "\n",
        "        # Setup output directory\n",
        "        CONFIG.save_dir = os.path.join('record', CONFIG.experiment_name)\n",
        "        os.makedirs(CONFIG.save_dir, exist_ok=True)\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(\n",
        "            filename=os.path.join(CONFIG.save_dir, 'log.txt'),\n",
        "            format='%(message)s',\n",
        "            level=logging.INFO,\n",
        "            filemode='a'\n",
        "        )\n",
        "\n",
        "        # Set experiment's device & deterministic behavior\n",
        "        if CONFIG.cpu:\n",
        "            CONFIG.device = 'cpu'\n",
        "        else:\n",
        "            CONFIG.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        torch.manual_seed(CONFIG.seed)\n",
        "        random.seed(CONFIG.seed)\n",
        "        np.random.seed(CONFIG.seed)\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.use_deterministic_algorithms(mode=True, warn_only=True)\n",
        "\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLG77qbMvmv2"
      },
      "source": [
        "## 1 - Activation Shaping module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2hsALKKq2SAZ"
      },
      "outputs": [],
      "source": [
        "def get_activation_shaping_hook(mask):\n",
        "    # The hook captures mask variable from the parent scope, to update it,\n",
        "    # remove() the hook and register a new one with the updated mask.\n",
        "\n",
        "    def activation_shaping_hook(module, input, output):\n",
        "\n",
        "        # binarize both activation map and mask using zero as threshold\n",
        "        # print(output.shape, mask.shape)\n",
        "        A_binary = torch.where(output <= 0, torch.tensor(0.0), torch.tensor(1.0))\n",
        "        M_binary = torch.where(mask <= 0, torch.tensor(0.0), torch.tensor(1.0))\n",
        "\n",
        "        # return the element-wise product of activation map and mask\n",
        "        shaped_output = A_binary * M_binary\n",
        "        # print(output.sum(), shaped_output.sum())\n",
        "        return shaped_output\n",
        "    return activation_shaping_hook\n",
        "\n",
        "class ASHResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ASHResNet18, self).__init__()\n",
        "        self.resnet = resnet18(pretrained=False)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 7)\n",
        "\n",
        "    def register_activation_shaping_hook(self, layer_name = 'layer4.1.relu', mask_out_ratio = 0.0):\n",
        "        self.layer_name = layer_name\n",
        "        self.mask_out_ratio = mask_out_ratio\n",
        "\n",
        "        # create a mask tensor with a given ratio of zeros\n",
        "        print('self.mask_out_ratio: ', self.mask_out_ratio)\n",
        "        rand_mat = torch.rand(512, 7, 7).to(CONFIG.device)\n",
        "        mask = torch.where(rand_mat <= self.mask_out_ratio, 0.0, 1.0).to(CONFIG.device)\n",
        "\n",
        "        hook = get_activation_shaping_hook(mask)\n",
        "        # penultimate_layer = self.resnet.layer4[1].bn2\n",
        "        # self.hook_handle = penultimate_layer.register_forward_hook(hook)\n",
        "\n",
        "        for name, module in self.resnet.named_modules():\n",
        "          if (isinstance(module, nn.ReLU) and name == self.layer_name):\n",
        "            print('Insert activation shaping layer after ', name, module)\n",
        "            self.hook_handle = module.register_forward_hook(hook)\n",
        "\n",
        "    def remove_activation_shaping_hook(self):\n",
        "        if self.hook_handle is not None:\n",
        "            self.hook_handle.remove()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34WzO42cvmv3"
      },
      "source": [
        "## 2 - Random Activation Maps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main_random():\n",
        "\n",
        "    # Load dataset\n",
        "    data = load_data()\n",
        "\n",
        "    # Load model\n",
        "    if CONFIG.experiment in ['random']:\n",
        "        model = ASHResNet18()\n",
        "        # model.register_activation_shaping_hook(layer_name = 'layer4.1.relu', mask_out_ratio = 0.55)\n",
        "        model.register_activation_shaping_hook(layer_name = 'layer4.0.relu', mask_out_ratio = 0.55)\n",
        "\n",
        "    model.to(CONFIG.device)\n",
        "\n",
        "    if not CONFIG.test_only:\n",
        "        train(model, data)\n",
        "    else:\n",
        "        evaluate(model, data['test'])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "    # Parse arguments (uncomment only one of the following)\n",
        "    '''\n",
        "    confs = [\n",
        "        { # Cartoon\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'random',\n",
        "            'experiment_name': 'random/cartoon/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'cartoon'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        }\n",
        "    ]\n",
        "    '''\n",
        "    '''\n",
        "    confs = [\n",
        "        { # Sketch\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'random',\n",
        "            'experiment_name': 'random/sketch/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'sketch'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        }\n",
        "    ]\n",
        "    '''\n",
        "    confs = [\n",
        "        { # Photo\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'random',\n",
        "            'experiment_name': 'random/photo/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'photo'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    #args = parse_arguments()\n",
        "    for conf in confs:\n",
        "        args = argparse.Namespace(**conf)\n",
        "        print(args)\n",
        "        CONFIG.update(vars(args))\n",
        "\n",
        "        # Setup output directory\n",
        "        CONFIG.save_dir = os.path.join('record', CONFIG.experiment_name)\n",
        "        os.makedirs(CONFIG.save_dir, exist_ok=True)\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(\n",
        "            filename=os.path.join(CONFIG.save_dir, 'log.txt'),\n",
        "            format='%(message)s',\n",
        "            level=logging.INFO,\n",
        "            filemode='a'\n",
        "        )\n",
        "\n",
        "        # Set experiment's device & deterministic behavior\n",
        "        if CONFIG.cpu:\n",
        "            CONFIG.device = 'cpu'\n",
        "        else:\n",
        "            CONFIG.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        torch.manual_seed(CONFIG.seed)\n",
        "        random.seed(CONFIG.seed)\n",
        "        np.random.seed(CONFIG.seed)\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.use_deterministic_algorithms(mode=True, warn_only=True)\n",
        "\n",
        "    main_random()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cprs-QFs3nWk",
        "outputId": "b1e0cca6-50ba-48ae-a44e-e91f7442eb37"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(seed=0, test_only=False, cpu=False, experiment='random', experiment_name='random/photo/', experiment_args='{}', dataset_args={'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'photo'}, batch_size=128, epochs=30, num_workers=5, grad_accum_steps=1)\n",
            "self.mask_out_ratio:  0.55\n",
            "Insert activation shaping layer after  layer4.0.relu ReLU(inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.64it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 25.87 - Loss: 0.01576805493074977 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.60it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.05 - Loss: 0.015808126812209625 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.65it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.71 - Loss: 0.015702521372698026 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.66it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.07 - Loss: 0.015656027751054593 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.69it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.83 - Loss: 0.015639504986608814 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.68it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.89 - Loss: 0.015524127526197605 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:11<00:00,  1.39it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.43 - Loss: 0.015527444256993825 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.70it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.31 - Loss: 0.015457651286781905 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.83it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  2.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.07 - Loss: 0.015445040728517635 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.95it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.01 - Loss: 0.015379162962565165 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.12it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.19 - Loss: 0.015333800758430344 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.11it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.01 - Loss: 0.015362573169662566 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.10it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.89 - Loss: 0.01526111442885713 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.10it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.83 - Loss: 0.01527670443414928 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.95it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  2.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.53 - Loss: 0.015268064615969173 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.84it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 25.87 - Loss: 0.01529640459014984 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.72it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.07 - Loss: 0.015198302126216317 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.69it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.95 - Loss: 0.01520213659651979 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.67it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.59 - Loss: 0.015191334378933477 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.69it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 25.69 - Loss: 0.01519078844321702 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.68it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.07 - Loss: 0.015112785165181417 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.67it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.53 - Loss: 0.0151487278367231 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.67it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.23 - Loss: 0.015130366251140297 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.68it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 27.01 - Loss: 0.015138322293401478 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.81it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  2.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.77 - Loss: 0.015120259944550291 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:08<00:00,  1.90it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.29 - Loss: 0.015129004838223943 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n",
            "100%|██████████| 14/14 [00:05<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.59 - Loss: 0.015102863133310558 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.00it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 25.87 - Loss: 0.015113375251164693 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.08it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.11 - Loss: 0.015128330199304455 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.07it/s]\n",
            "100%|██████████| 14/14 [00:06<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.35 - Loss: 0.015114920938800194 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84SPtogfvmv3"
      },
      "source": [
        "## 3 - Adapting Activation Maps across Domains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMwxcUU9vmv3"
      },
      "source": [
        "## Ext. 2 - Binarization Ablation"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}