{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j4ramm0vmvh"
      },
      "source": [
        "# Domain Adaptation Via Activation Shaping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-LqKzY-vmvp"
      },
      "source": [
        "**Teacher assistant** Iurada Leonardo\n",
        "\n",
        "**Students**\n",
        "\n",
        "- Bar Giorgio\n",
        "- Distefano Giuseppe\n",
        "- Incaviglia Salvatore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1K5BCgevmvr"
      },
      "source": [
        "## 0 - Reproduce the Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GNDC97Lvmvs"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yj0xpGOvmvs",
        "outputId": "e79de94c-4443-4e05-e790-a707652768ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision tqdm torchmetrics\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.backends.mps\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import os\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QL6QFg7vmvv"
      },
      "source": [
        "### Setup PACS dataset and environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU25YTvRvmvw",
        "outputId": "665ff313-b8e1-451a-ee55-8feba6717e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 10032, done.\u001b[K\n",
            "remote: Total 10032 (delta 0), reused 0 (delta 0), pack-reused 10032\u001b[K\n",
            "Receiving objects: 100% (10032/10032), 174.13 MiB | 26.97 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (9993/9993), done.\n",
            "Cloning into 'DANN_Template'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23\u001b[K\n",
            "Receiving objects: 100% (23/23), 33.86 KiB | 963.00 KiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ],
      "source": [
        "# Download PACS Dataset Images and Labels\n",
        "!git clone https://github.com/MachineLearning2020/Homework3-PACS/\n",
        "!git clone https://github.com/silvia1993/DANN_Template/\n",
        "\n",
        "# Setup data\n",
        "!rm -rf data || true\n",
        "!rm -rf record || true\n",
        "!mkdir data\n",
        "!mkdir data/kfold\n",
        "!cp -r Homework3-PACS/PACS/ data/kfold\n",
        "!cp DANN_Template/txt_lists/*.txt data\n",
        "!rm -rf Homework3-PACS/\n",
        "!rm -rf DANN_Template/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCGGDU0Yvmvx"
      },
      "source": [
        "### Globals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks2GUIKUvmvx"
      },
      "source": [
        "#### globals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CKy4Lcn5vmvy"
      },
      "outputs": [],
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "CONFIG = dotdict({})\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    CONFIG.device = 'cuda'\n",
        "elif torch.backends.mps.is_available() and \\\n",
        "    torch.backends.mps.is_built():\n",
        "    CONFIG.device = 'mps'\n",
        "else:\n",
        "    CONFIG.device = 'cpu'\n",
        "\n",
        "CONFIG.dtype = torch.float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X-3ocOEvmvy"
      },
      "source": [
        "#### parse args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ri1QrU7_vmvz"
      },
      "outputs": [],
      "source": [
        "def _clear_args(parsed_args):\n",
        "    parsed_args.experiment_args = eval(parsed_args.experiment_args)\n",
        "    parsed_args.dataset_args = eval(parsed_args.dataset_args)\n",
        "    return parsed_args\n",
        "\n",
        "\n",
        "def parse_arguments():\n",
        "    parser = ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--seed', type=int, default=0, help='Seed used for deterministic behavior')\n",
        "    parser.add_argument('--test_only', action='store_true', help='Whether to skip training')\n",
        "    parser.add_argument('--cpu', action='store_true', help='Whether to force the usage of CPU')\n",
        "\n",
        "    parser.add_argument('--experiment', type=str, default='baseline')\n",
        "    parser.add_argument('--experiment_name', type=str, default='baseline')\n",
        "    parser.add_argument('--experiment_args', type=str, default='{}')\n",
        "    parser.add_argument('--dataset_args', type=str, default='{}')\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=128)\n",
        "    parser.add_argument('--epochs', type=int, default=30)\n",
        "    parser.add_argument('--num_workers', type=int, default=5)\n",
        "    parser.add_argument('--grad_accum_steps', type=int, default=1)\n",
        "\n",
        "    return _clear_args(parser.parse_args())\n",
        "\n",
        "\n",
        "def parse_fake_arguments(conf):\n",
        "    parser = ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--seed', type=int, default=0, help='Seed used for deterministic behavior')\n",
        "    parser.add_argument('--test_only', action='store_true', help='Whether to skip training')\n",
        "    parser.add_argument('--cpu', action='store_true', help='Whether to force the usage of CPU')\n",
        "\n",
        "    parser.add_argument('--experiment', type=str, default='baseline')\n",
        "    #parser.add_argument('--experiment_name', type=str, default='baseline')\n",
        "    if conf=='cartoon': parser.add_argument('--experiment_name', type=str, default='baseline/cartoon')\n",
        "    elif conf=='sketch': parser.add_argument('--experiment_name', type=str, default='baseline/sketch')\n",
        "    elif conf=='photo': parser.add_argument('--experiment_name', type=str, default='baseline/photo')\n",
        "    else: parser.add_argument('--experiment_name', type=str, default='baseline/cartoon')\n",
        "    parser.add_argument('--experiment_args', type=str, default='{}')\n",
        "    #parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': '${target_domain}'}\")\n",
        "    if conf=='cartoon': parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': 'cartoon'}\")\n",
        "    elif conf=='sketch': parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': 'sketch'}\")\n",
        "    elif conf=='photo': parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': 'photo'}\")\n",
        "    else: parser.add_argument('--dataset_args', type=str, default=\"{'root': 'data/PACS', 'source_domain': 'art_painting', 'target_domain': 'cartoon'}\")\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=128)\n",
        "    parser.add_argument('--epochs', type=int, default=30)\n",
        "    parser.add_argument('--num_workers', type=int, default=5)\n",
        "    parser.add_argument('--grad_accum_steps', type=int, default=1)\n",
        "\n",
        "    return _clear_args(parser.parse_args())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7_xoRWhvmvz"
      },
      "source": [
        "#### Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GA15sREQvmvz"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "NUM_CLASSES = 7\n",
        "BATCH_SIZE = 256\n",
        "LR = 1e-3               # The initial Learning Rate\n",
        "MOMENTUM = 0.9          # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5     # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 30         # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20          # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1             # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjcULfoOvmv0"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2juNIEQ9vmv0"
      },
      "source": [
        "#### utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XSPzZSuSvmv0"
      },
      "outputs": [],
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, examples, transform):\n",
        "        self.examples = examples\n",
        "        self.T = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.examples[index]\n",
        "        x = Image.open(x).convert('RGB')\n",
        "        x = self.T(x).to(CONFIG.dtype)\n",
        "        y = torch.tensor(y).long()\n",
        "        return x, y\n",
        "\n",
        "######################################################\n",
        "# TODO: modify 'BaseDataset' for the Domain Adaptation setting.\n",
        "# Hint: randomly sample 'target_examples' to obtain targ_x\n",
        "#class DomainAdaptationDataset(Dataset):\n",
        "#    def __init__(self, source_examples, target_examples, transform):\n",
        "#        self.source_examples = source_examples\n",
        "#        self.target_examples = target_examples\n",
        "#        self.T = transform\n",
        "#\n",
        "#    def __len__(self):\n",
        "#        return len(self.source_examples)\n",
        "#\n",
        "#    def __getitem__(self, index):\n",
        "#        src_x, src_y = ...\n",
        "#        targ_x = ...\n",
        "#\n",
        "#        src_x = self.T(src_x)\n",
        "#        targ_x = self.T(targ_x)\n",
        "#        return src_x, src_y, targ_x\n",
        "\n",
        "# [OPTIONAL] TODO: modify 'BaseDataset' for the Domain Generalization setting.\n",
        "# Hint: combine the examples from the 3 source domains into a single 'examples' list\n",
        "#class DomainGeneralizationDataset(Dataset):\n",
        "#    def __init__(self, examples, transform):\n",
        "#        self.examples = examples\n",
        "#        self.T = transform\n",
        "#\n",
        "#    def __len__(self):\n",
        "#        return len(self.examples)\n",
        "#\n",
        "#    def __getitem__(self, index):\n",
        "#        x1, x2, x3 = self.examples[index]\n",
        "#        x1, x2, x3 = self.T(x1), self.T(x2), self.T(x3)\n",
        "#        targ_x = self.T(targ_x)\n",
        "#        return x1, x2, x3\n",
        "\n",
        "######################################################\n",
        "\n",
        "class SeededDataLoader(DataLoader):\n",
        "    def __init__(self, dataset: Dataset, batch_size=1, shuffle=None,\n",
        "                 sampler=None,\n",
        "                 batch_sampler=None,\n",
        "                 num_workers=0, collate_fn=None,\n",
        "                 pin_memory=False, drop_last=False, timeout=0,\n",
        "                 worker_init_fn=None, multiprocessing_context=None,\n",
        "                 generator=None, *, prefetch_factor=None, persistent_workers=False,\n",
        "                 pin_memory_device=\"\"):\n",
        "\n",
        "        if not CONFIG.use_nondeterministic:\n",
        "            def seed_worker(worker_id):\n",
        "                worker_seed = torch.initial_seed() % 2**32\n",
        "                np.random.seed(worker_seed)\n",
        "                random.seed(worker_seed)\n",
        "\n",
        "            generator = torch.Generator()\n",
        "            generator.manual_seed(CONFIG.seed)\n",
        "\n",
        "            worker_init_fn = seed_worker\n",
        "\n",
        "        super().__init__(dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn,\n",
        "                         pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator,\n",
        "                         prefetch_factor=prefetch_factor, persistent_workers=persistent_workers,\n",
        "                         pin_memory_device=pin_memory_device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8COjLe2Fvmv0"
      },
      "source": [
        "#### PACS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qJ3cq4Ofvmv1"
      },
      "outputs": [],
      "source": [
        "def get_transform(size, mean, std, preprocess):\n",
        "    transform = []\n",
        "    if preprocess:\n",
        "        transform.append(T.Resize(256))\n",
        "        transform.append(T.RandomResizedCrop(size=size, scale=(0.7, 1.0)))\n",
        "        transform.append(T.RandomHorizontalFlip())\n",
        "    else:\n",
        "        transform.append(T.Resize(size))\n",
        "    transform.append(T.ToTensor())\n",
        "    transform.append(T.Normalize(mean, std))\n",
        "    return T.Compose(transform)\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    CONFIG.num_classes = 7\n",
        "    CONFIG.data_input_size = (3, 224, 224)\n",
        "\n",
        "    # Create transforms\n",
        "    mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225) # ImageNet Pretrain statistics\n",
        "    train_transform = get_transform(size=224, mean=mean, std=std, preprocess=True)\n",
        "    test_transform = get_transform(size=224, mean=mean, std=std, preprocess=False)\n",
        "\n",
        "    # Load examples & create Dataset\n",
        "    if CONFIG.experiment in ['baseline']:\n",
        "        source_examples, target_examples = [], []\n",
        "\n",
        "        # Load source\n",
        "        #with open(os.path.join(CONFIG.dataset_args['text_root'], f\"{CONFIG.dataset_args['source_domain']}.txt\"), 'r') as f:\n",
        "            #lines = f.readlines()\n",
        "        # domain/category/sample n\n",
        "        f = open(os.path.join(CONFIG.dataset_args['text_root'], f\"{CONFIG.dataset_args['source_domain']}.txt\"), 'r')\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            path, label = line[0].split('/')[0:], int(line[1])\n",
        "            source_examples.append((os.path.join(CONFIG.dataset_args['images_root'], *path), label))\n",
        "        f.close()\n",
        "\n",
        "        # Load target\n",
        "        #with open(os.path.join(CONFIG.dataset_args['text_root'], f\"{CONFIG.dataset_args['target_domain']}.txt\"), 'r') as f:\n",
        "            #lines = f.readlines()\n",
        "        f = open(os.path.join(CONFIG.dataset_args['text_root'], f\"{CONFIG.dataset_args['target_domain']}.txt\"), 'r')\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            path, label = line[0].split('/')[0:], int(line[1])\n",
        "            target_examples.append((os.path.join(CONFIG.dataset_args['images_root'], *path), label))\n",
        "        f.close()\n",
        "\n",
        "        train_dataset = BaseDataset(source_examples, transform=train_transform)\n",
        "        test_dataset = BaseDataset(target_examples, transform=test_transform)\n",
        "\n",
        "    ######################################################\n",
        "    #elif... TODO: Add here how to create the Dataset object for the other experiments\n",
        "\n",
        "\n",
        "    ######################################################\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader = SeededDataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=CONFIG.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=CONFIG.num_workers,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    test_loader = SeededDataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=CONFIG.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=CONFIG.num_workers,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    return {'train': train_loader, 'test': test_loader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDUK98dRvmv1"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRb0wPBTvmv1"
      },
      "source": [
        "#### ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RT5Z64b0vmv1"
      },
      "outputs": [],
      "source": [
        "class BaseResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseResNet18, self).__init__()\n",
        "        self.resnet = resnet18(weights=ResNet18_Weights)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "######################################################\n",
        "# TODO: either define the Activation Shaping Module as a nn.Module\n",
        "#class ActivationShapingModule(nn.Module):\n",
        "#...\n",
        "#\n",
        "# OR as a function that shall be hooked via 'register_forward_hook'\n",
        "#def activation_shaping_hook(module, input, output):\n",
        "#...\n",
        "#\n",
        "######################################################\n",
        "# TODO: modify 'BaseResNet18' including the Activation Shaping Module\n",
        "#class ASHResNet18(nn.Module):\n",
        "#    def __init__(self):\n",
        "#        super(ASHResNet18, self).__init__()\n",
        "#        ...\n",
        "#\n",
        "#    def forward(self, x):\n",
        "#        ...\n",
        "#\n",
        "######################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSD7qmGTvmv2"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98_3TWLTvmv2",
        "outputId": "e87234e0-8e72-4eed-b366-348499a9998b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:11<00:00,  1.38it/s]\n",
            "100%|██████████| 14/14 [00:08<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 60.78 - Loss: 0.011621099460624649 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:12<00:00,  1.25it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 79.76 - Loss: 0.006603041344773983 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.54it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 87.78 - Loss: 0.004115445813732947 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.56it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 89.34 - Loss: 0.0031028472110182937 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.14 - Loss: 0.002496956926798392 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.56it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 92.28 - Loss: 0.0021861916619860485 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.50it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 92.69 - Loss: 0.0019660448198189993 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.52it/s]\n",
            "100%|██████████| 14/14 [00:07<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.17 - Loss: 0.0018036964098493496 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.65it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.53 - Loss: 0.001719868522204325 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.13 - Loss: 0.001576710202379855 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.63it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.25 - Loss: 0.0015135072863209033 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.66it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.37 - Loss: 0.0014603539944408896 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.58it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.91 - Loss: 0.0013093235629225918 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.58it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.91 - Loss: 0.0013378519051803087 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.91 - Loss: 0.0013170251901635152 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.56it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.21 - Loss: 0.0012475210615617786 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.56it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.69 - Loss: 0.0011850444800750224 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.60it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.81 - Loss: 0.0011461620620580133 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.55it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.39 - Loss: 0.0011814452841610252 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.55it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.51 - Loss: 0.0011256425245525594 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.59it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.63 - Loss: 0.0011001161991166855 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.75 - Loss: 0.0010893491074487477 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.56it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.93 - Loss: 0.001060648531859328 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.69 - Loss: 0.001080870129234955 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.56it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.75 - Loss: 0.0010906890497548495 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.56it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.75 - Loss: 0.001076280142732723 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.59it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.75 - Loss: 0.0010754830036646948 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.55it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.87 - Loss: 0.001072935420395193 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.69 - Loss: 0.0010834365876804212 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n",
            "100%|██████████| 14/14 [00:04<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.93 - Loss: 0.0010702309064834774 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "\n",
        "    acc_meter = Accuracy(task='multiclass', num_classes=CONFIG.num_classes)\n",
        "    acc_meter = acc_meter.to(CONFIG.device)\n",
        "\n",
        "    loss = [0.0, 0]\n",
        "    for x, y in tqdm(data):\n",
        "        with torch.autocast(device_type=CONFIG.device, dtype=torch.float16, enabled=True):\n",
        "            x, y = x.to(CONFIG.device), y.to(CONFIG.device)\n",
        "            logits = model(x)\n",
        "            acc_meter.update(logits, y)\n",
        "            loss[0] += F.cross_entropy(logits, y).item()\n",
        "            loss[1] += x.size(0)\n",
        "\n",
        "    accuracy = acc_meter.compute()\n",
        "    loss = loss[0] / loss[1]\n",
        "    logging.info(f'Accuracy: {100 * accuracy:.2f} - Loss: {loss}')\n",
        "    print(f'Accuracy: {100 * accuracy:.2f} - Loss: {loss} \\n')\n",
        "\n",
        "\n",
        "def train(model, data):\n",
        "\n",
        "    # Create optimizers & schedulers\n",
        "    optimizer = torch.optim.SGD(model.parameters(), weight_decay=0.0005, momentum=0.9, nesterov=True, lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(CONFIG.epochs * 0.8), gamma=0.1)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "\n",
        "    # Load checkpoint (if it exists)\n",
        "    cur_epoch = 0\n",
        "    if os.path.exists(os.path.join('record', CONFIG.experiment_name, 'last.pth')):\n",
        "        checkpoint = torch.load(os.path.join('record', CONFIG.experiment_name, 'last.pth'))\n",
        "        cur_epoch = checkpoint['epoch']\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "\n",
        "    # Optimization loop\n",
        "    for epoch in range(cur_epoch, CONFIG.epochs):\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, batch in enumerate(tqdm(data['train'])):\n",
        "\n",
        "            # Compute loss\n",
        "            with torch.autocast(device_type=CONFIG.device, dtype=torch.float16, enabled=True):\n",
        "\n",
        "                if CONFIG.experiment in ['baseline']:\n",
        "                    x, y = batch\n",
        "                    x, y = x.to(CONFIG.device), y.to(CONFIG.device)\n",
        "                    loss = F.cross_entropy(model(x), y)\n",
        "\n",
        "                ######################################################\n",
        "                #elif... TODO: Add here train logic for the other experiments\n",
        "\n",
        "                ######################################################\n",
        "\n",
        "            # Optimization step\n",
        "            scaler.scale(loss / CONFIG.grad_accum_steps).backward()\n",
        "\n",
        "            if ((batch_idx + 1) % CONFIG.grad_accum_steps == 0) or (batch_idx + 1 == len(data['train'])):\n",
        "                scaler.step(optimizer)\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                scaler.update()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Test current epoch\n",
        "        logging.info(f'[TEST @ Epoch={epoch}]')\n",
        "        evaluate(model, data['test'])\n",
        "\n",
        "        # Save checkpoint\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'model': model.state_dict()\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join('record', CONFIG.experiment_name, 'last.pth'))\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Load dataset\n",
        "    data = load_data()\n",
        "\n",
        "    # Load model\n",
        "    if CONFIG.experiment in ['baseline']:\n",
        "        model = BaseResNet18()\n",
        "\n",
        "    ######################################################\n",
        "    #elif... TODO: Add here model loading for the other experiments (eg. DA and optionally DG)\n",
        "\n",
        "    ######################################################\n",
        "\n",
        "    model.to(CONFIG.device)\n",
        "\n",
        "    if not CONFIG.test_only:\n",
        "        train(model, data)\n",
        "    else:\n",
        "        evaluate(model, data['test'])\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "    # Parse arguments\n",
        "    confs = [\n",
        "        { # Cartoon\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'baseline',\n",
        "            'experiment_name': 'baseline/cartoon/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'cartoon'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        },\n",
        "        { # Sketch\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'baseline',\n",
        "            'experiment_name': 'baseline/sketch/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'sketch'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        },\n",
        "        { # Photo\n",
        "            'seed': 0,\n",
        "            'test_only': False,\n",
        "            'cpu': False,\n",
        "            'experiment': 'baseline',\n",
        "            'experiment_name': 'baseline/photo/',\n",
        "            'experiment_args': '{}',\n",
        "            'dataset_args': {'text_root': 'data', 'images_root': 'data/kfold/PACS', 'source_domain': 'art_painting', 'target_domain': 'photo'},\n",
        "            'batch_size': 128,\n",
        "            'epochs': 30,\n",
        "            'num_workers': 5,\n",
        "            'grad_accum_steps': 1\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    #args = parse_arguments()\n",
        "    for conf in confs:\n",
        "        args = argparse.Namespace(**conf)\n",
        "        CONFIG.update(vars(args))\n",
        "\n",
        "        # Setup output directory\n",
        "        CONFIG.save_dir = os.path.join('record', CONFIG.experiment_name)\n",
        "        os.makedirs(CONFIG.save_dir, exist_ok=True)\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(\n",
        "            filename=os.path.join(CONFIG.save_dir, 'log.txt'),\n",
        "            format='%(message)s',\n",
        "            level=logging.INFO,\n",
        "            filemode='a'\n",
        "        )\n",
        "\n",
        "        # Set experiment's device & deterministic behavior\n",
        "        if CONFIG.cpu:\n",
        "            CONFIG.device = 'cpu'\n",
        "        else:\n",
        "            CONFIG.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        torch.manual_seed(CONFIG.seed)\n",
        "        random.seed(CONFIG.seed)\n",
        "        np.random.seed(CONFIG.seed)\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.use_deterministic_algorithms(mode=True, warn_only=True)\n",
        "\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLG77qbMvmv2"
      },
      "source": [
        "## 1 - Activation Shaping module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34WzO42cvmv3"
      },
      "source": [
        "## 2 - Random Activation Maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84SPtogfvmv3"
      },
      "source": [
        "## 3 - Adapting Activation Maps across Domains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMwxcUU9vmv3"
      },
      "source": [
        "## Ext. 2 - Binarization Ablation"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}